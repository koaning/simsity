{"config":{"lang":["en"],"separator":"[\\s\\-]+"},"docs":[{"title":"Home","text":"<p></p> <p>simsity</p>  <p>Simsity is a Super Simple Similarities Service[tm].  It's all about building a neighborhood. Literally! </p>  <p> This project contains simple tools to help in similarity retreival scenarios by making a convientwrapper around encoding strategies as well as nearest neighbor approaches. Typical usecases include early stage bulk labelling and duplication discovery.</p>","location":""},{"title":"Installation","text":"<p>You can install simsity via <code>pip</code>.</p> <pre><code>python -m pip install simsity\n</code></pre>","location":"#installation"},{"title":"Getting Started","text":"<p>If you'd like to get started, we recommend starting here.</p>","location":"#getting-started"},{"title":"Related Projects","text":"<p>This tool becomes even more powerful when you combine it with existing tools. In particular this library was designed to work well with:</p> <ul> <li>scikit-learn for general encoding tools and pipelines</li> <li>embetter for encoding tools on text/image data</li> <li>dirty_cat for encoding tools on dirty categorical data</li> </ul>","location":"#related-projects"},{"title":"API Details","text":"","location":"api/"},{"title":"Service","text":"<p>This object represents a nearest neighbor lookup service. You can pass it an encoder and a method to index the data.</p> <p>Arguments:     - encoder: A scikit-learn compatible encoder for the input.     - indexer: A compatible indexer for the nearest neighbor search.</p>","location":"api/#service"},{"title":"Indexer Features","text":"<p>The table below shows the features of each indexer.</p>    name support sparse support save incremental_index     <code>AnnoyIndexer</code> no yes no   <code>PynnDescentIndexer</code> yes yes no    <p>These can be loaded via:</p> <pre><code>from simsity.datasets import fetch_clinc, fetch_recipe, fetch_voters\n</code></pre>","location":"api/#indexer-features"},{"title":"Data Loaders","text":"<p>This library has a few data loaders so that you can play with data.</p> <ul> <li><code>fetch_clinc</code> loads an intent detection dataset with 150+ intents</li> <li><code>fetch_recipe</code> loads a dataset with recipes titles</li> <li><code>fetch_voters</code> loads a dataset with voter information that contain typos</li> </ul> <p>They can be loaded via:</p> <pre><code>from simsity.datasets import fetch_clinc, fetch_recipe, fetch_voters\n</code></pre>","location":"api/#data-loaders"},{"title":"Quickstart","text":"<p>The goal of this tool is to offer you a simple similarity service.</p> <p>So let's build an example! We'll build a similarity searching tool for a text dataset.</p>","location":"guides/"},{"title":"Install","text":"<p>In this tutorial we will leverage pretrained language models that are provided via embetter. We will install that, together with simsity.</p> <pre><code>python -m pip install simsity \"embetter[sentence-tfm]\"\n</code></pre> <p>The install can take a while, because we are downloading PyTorch.</p>","location":"guides/#install"},{"title":"Example Data","text":"<p>For this tutorial we will explore a set of recipe names.</p> <pre><code>from simsity.datasets import fetch_recipes\n\ndf_recipes = fetch_recipes()\n</code></pre> <p>Here's what the top 5 rows look like.</p>    text     pork chop noodle soup   5 ingredient almond cake with fresh berries   shrimp cakes   chili roasted okra   slow cooker chicken chili    <p>The goal is to be able to look for recipes without resorting to strict token equality. If we look for \"meat\" we'd like to see recipes that have meat in it, even if the word \"meat\" does not appear in the recipe title.</p> <p>We will work with a list of texts in this tutorial.</p> <pre><code>recipes = list(df_recipes['text'])\n</code></pre>","location":"guides/#example-data"},{"title":"The Tactic","text":"<p>The idea is that we're going to split the problem of similarity search into two subproblems.</p> <ol> <li>The first problem is encoding. If we're going to use similarities, we'll need some way to turn our data into a numeric representation. Without a numeric representation it'll be quite hard to compare items numerically.</li> <li>The second problem is indexing. Even when we have numeric representations to compare against, we don't want to compare all the possible solutions out there. Instead we'd prefer to index out data such that it's fast to retreive.</li> </ol> <p>To solve the first problem, simsity likes to re-use tools from the scikit-learn ecosystem. An encoder in simsity is simply a scikit-learn component/pipeline that transforms data. To solve the second problem, simsity wraps around existing tools for approximate nearest-neighbor lookup. The goal of simsity is to combine an encoder and an indexer into a service that's convenient for interaction.</p>","location":"guides/#the-tactic"},{"title":"Example Encoder","text":"<p>We will now define a scikit-learn compatible encoder, which is provided by embetter in this case.</p> <pre><code>from embetter.text import SentenceEncoder\n\n# The encoder defines how we encode the data going in.\nencoder = SentenceEncoder()\n</code></pre>","location":"guides/#example-encoder"},{"title":"Example Indexer","text":"<p>Simsity provides indexers by wrapping around existing solutions. In particular it supports annoy out of the box.  If you're curious to learn how it works, you may appreciate this segment on calmcode.</p> <pre><code>from simsity.indexer import AnnoyIndexer\n\n# Create an indexer\nindexer = AnnoyIndexer()\n</code></pre> <p>There are many distance metrics that annoy supports; <code>angular</code>, <code>euclidean</code>, <code>manhattan</code>, <code>hamming</code> and <code>dot</code>.</p>  <p>Note</p> <p>There are differences between indexers. Annoy is flexible, but you may need to add many trees for it to become accurate. It also only supports sparse arrays. The <code>PyNNDescentIndexer</code> indexer supports dense arrays as well as sparse ones! The only downside is that it does take a while to index all the data.</p>","location":"guides/#example-indexer"},{"title":"Building a Service","text":"<p>Once you have an encoder and an indexer, you can construct a service.</p> <pre><code>from simsity.service import Service\n\n# The service combines the two into a single object.\nservice = Service(indexer=indexer, encoder=encoder)\n</code></pre> <p>This service can now index on your dataset. It will start by first training the encoder pipeline. After that the data will be transformed and indexed by the indexer. All of this will be handled by the following call:</p> <pre><code>service.index(recipes)\n</code></pre> <p>It's good to notice that we're being explicit here about which features are being used. We're telling our service to only consider the <code>\"text\"</code> column! This is important when you want to query your data.</p>","location":"guides/#building-a-service"},{"title":"Query the Data","text":"<p>You can now try to look for similar items by sending a query to the service. Note that the keyword argument <code>text=</code> corresponds with the features that we chose to index earlier.</p> <pre><code># Get indices and distances\nidx, dists = service.query(text=\"meat\", n_neighbors=10, out=\"dataframe\")\n\n# Show as pandas dataframe\nimport pandas as pd\npd.DataFrame({\"recipe\": recipes}).iloc[idx].assign(dists=dists)\n</code></pre> <p>This is the table that you'll get back.</p>    recipe dists     roast beef 0.840229   beef stew 0.851083   buffalo chicken meatballs 0.853497   meat feast pizza 0.873777   chicken marsala meatballs 0.874075   meat dim sum 0.886897   moroccan meatballs 0.892015   meatball sub sandwich 0.899369   italian meatballs 0.899428   juicy italian meatballs 0.906681    <p>The quality of what you get back depends on the data that you give the system, the encoding and the indexer that you pick. You can probably improve the results by picking an angular distance measure in annoy, but you could also try out other embedding models as well.</p> <p>The goal of this package is to make it easy to interact and experiment with the idea of \"building neigborhoods of similar items\". Hence the name: simsity.</p>","location":"guides/#query-the-data"},{"title":"All Code","text":"<p>Here's the full code block that we've used in this section.</p> <pre><code>import pandas as pd\nfrom embetter.text import SentenceEncoder\n\nfrom simsity.datasets import fetch_recipes\nfrom simsity.service import Service\nfrom simsity.indexer import AnnoyIndexer\n\n\n# Fetch data\ndf_recipes = fetch_recipes()\nrecipes = df_recipes['text']\n\n# Create an indexer\nindexer = AnnoyIndexer()\n\n# The service combines the two into a single object.\nservice = Service(indexer=indexer, encoder=encoder)\n\n# We can now build the service using this data.\nservice.index(recipes)\n\n# And use it\nidx, dists = service.query(\"meat\", n_neighbors=10)\n\nres = (pd.DataFrame({\"recipe\": recipes})\n    .iloc[idx]\n    .assign(dists=dists)\n    .to_markdown(index=False)\n)\n\n# Show results\nprint(res)\n</code></pre>","location":"guides/#all-code"},{"title":"Deduplication","text":"<p>An interesting use-case for simsity is to use it as a tool that explores deduplication.</p>","location":"guides/dedup/"},{"title":"Example","text":"<p>Let's consider the <code>voters</code> dataset.</p> <pre><code>from simsity.datasets import fetch_voters\n\ndf = fetch_voters()\n</code></pre>    name suburb postcode     khimerc thomas charlotte 2826g   lucille richardst kannapolis 28o81   reb3cca bauerboand raleigh 27615   maleda mccloud goldsboro 2753o   belida stovall morrisvill 27560    <p>This dataset contains information about \"voters\" and the concern is that some of these rows may represent the same person. The persons name might occur in different spellings and the postcodes may contain typos, but they could still refer to the same person. In other words; there may be duplicates in this dataframe that we cannot remove with <code>.drop_duplicates()</code>. So how might we go about finding these?</p>","location":"guides/dedup/#example"},{"title":"Similarity Service!","text":"<p>Let's build a similarity service, but now we'll use encoders from the dirty_cat package. These encoders are designed to handle dirty categorical data, which would be perfect for our use-case here.</p> <pre><code>from simsity.service import Service\nfrom simsity.indexer import AnnoyIndexer\nfrom dirty_cat import GapEncoder\n\n# Set up\nindexer = AnnoyIndexer(n_trees=50)\nencoder = GapEncoder().fit(df)\nservice = Service(indexer=indexer, encoder=encoder)\n\n# Index\nservice.index(df)\n</code></pre>","location":"guides/dedup/#similarity-service"},{"title":"Query","text":"<p>If we now want to construct a query, we will need to send a pandas row. The encoder assumes pandas, so we need to make sure our query is compatible.</p> <pre><code># Query as a dictionary\ndict_in = dict(name=\"khimerc thmas\", suburb=\"chariotte\", postcode=\"28273\")\n# Single row from dataframe\nq_in = pd.DataFrame([dict_in]).iloc[0]\n\nidx, dists = service.query(q_in, n_neighbors=10)\ndf.iloc[idx].assign(dist=dists)\n</code></pre> <p>This is the dataframe that we get out.</p>    name suburb postcode dist     chimerc thmas chaflotte 28269 3.14833   chimerc thomas charlotte 28269 3.95177   khimerc thomas charlotte 2826g 3.98925   angelique deas charlotte 28278 4.76251   barbara dambrosio charlotte 28277 5.46748   kendel beachum charlotte 28226 5.6414   mariq simpsony charlotte 28269 6.76645   herber oxendine charlotte 28247 8.22691   steven twamley chapel hill 27514 8.97374   herbert oxendin chsrlotte 28277 9.53476    <p>It certainly seems like we have some duplicates in here! So we may be able to use retreival/embedding tricks for that use-case.</p> <p>It deserves mentioning, once again, that the quality of our retreival depends a lot on our choice of index and encoding. But experimenting with this is exactly what this library makes easy.</p>","location":"guides/dedup/#query"}]}